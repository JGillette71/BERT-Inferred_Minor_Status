{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_inferred_minor_status_v3.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1HZ-5evPOxRJMbGxWwBXy75NpCaFZYyNf",
      "authorship_tag": "ABX9TyPj1evOppgc8aZXcBGXyjH1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JGillette71/BERT-Inferred_Minor_Status/blob/main/bert_inferred_minor_status_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction\n",
        "**Inferrence of Minor Status for Data Protections** \\\n",
        "Initial BERT based approach v1 \\\n",
        "NER - Token-level Classification \\\n",
        "Jason Gillette \n",
        "\n",
        "**Fine-tuning Data**\\\n",
        "Global Giving Storytelling Project \\\n",
        "*57,220 stories collected in Uganda and Kenya*\\\n",
        "Source: marcmaxmeister, data.world \\\n",
        "https://data.world/marcmaxmeister/globalgiving-storytelling-project/workspace/file?filename=storytelling-project-feb-2013.csv \\\n",
        "Annotator: Jason Gillette \\\n",
        "IOB Labels \\\n",
        "Classes:\n",
        "- ADULT\n",
        "- MINOR\n",
        "- ~~LOCATION~~\n",
        "- ~~ORGANIZATION~~ \n",
        "- ~~OTHER~~"
      ],
      "metadata": {
        "id": "FD1zB56C4ytJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Processing"
      ],
      "metadata": {
        "id": "LD2_JCQH5OzJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpXthm5b4Str"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read fine tuning data \n",
        "train_data = pd.read_excel('/content/drive/MyDrive/Grad School Projects /training_data_v3.xlsx')\n",
        "train_data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GVjB9B05wtd",
        "outputId": "0a6bd2bd-5e6b-45b8-e809-0ddf412406ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2027 entries, 0 to 2026\n",
            "Data columns (total 2 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   sentence_list  2027 non-null   object\n",
            " 1   label_list     2027 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 31.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read testing data (non augmented sequences)\n",
        "test_data = pd.read_excel('/content/drive/MyDrive/Grad School Projects /testing_data_v3.xlsx')\n",
        "test_data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXgGdQRYT-fH",
        "outputId": "264871e1-7a9b-4ef7-e77a-963b0a2275f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 507 entries, 0 to 506\n",
            "Data columns (total 2 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   sentence_list  507 non-null    object\n",
            " 1   label_list     507 non-null    object\n",
            "dtypes: object(2)\n",
            "memory usage: 8.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check for nans \n",
        "train_data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcaeTSKpBhan",
        "outputId": "ba3355da-647b-47b3-9cf3-0a76ec4e3652"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentence_list    0\n",
              "label_list       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check for duplicates in augmented sequences \n",
        "train_data['sentence_list'].duplicated().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-3j9vnhC4LT",
        "outputId": "fcd07304-843c-4808-8b9c-4efbeb754f74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Analysis"
      ],
      "metadata": {
        "id": "F9IBZIk7NEKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "J9Ru76mPNA_q",
        "outputId": "a353a573-e2ef-4fed-ce2b-786debb2c4e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       sentence_list  \\\n",
              "0  Stealing is the taking of someone 's property ...   \n",
              "1  Kanyeki was a student at Olkesuke primary scho...   \n",
              "2  There was a boy living up country by a name ca...   \n",
              "3  I am Petronila Wilunda . I am currently on a b...   \n",
              "4  My name is Jane Wilunda , from Kakamega North ...   \n",
              "\n",
              "                                          label_list  \n",
              "0  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
              "1  B-MINR,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O...  \n",
              "2  O,O,O,O,O,O,O,O,O,O,O,B-MINR,I-MINR,O,O,O,O,O,...  \n",
              "3  O,O,B-MINR,I-MINR,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
              "4  O,O,O,B-MINR,I-MINR,O,O,O,O,O,O,O,O,O,O,O,O,O,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f932c375-69c0-42f3-80bf-07bff672e9d3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_list</th>\n",
              "      <th>label_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Stealing is the taking of someone 's property ...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Kanyeki was a student at Olkesuke primary scho...</td>\n",
              "      <td>B-MINR,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>There was a boy living up country by a name ca...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,B-MINR,I-MINR,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I am Petronila Wilunda . I am currently on a b...</td>\n",
              "      <td>O,O,B-MINR,I-MINR,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>My name is Jane Wilunda , from Kakamega North ...</td>\n",
              "      <td>O,O,O,B-MINR,I-MINR,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f932c375-69c0-42f3-80bf-07bff672e9d3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f932c375-69c0-42f3-80bf-07bff672e9d3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f932c375-69c0-42f3-80bf-07bff672e9d3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# instances of each entity class in training data\n",
        "\n",
        "# convert to list\n",
        "train_data['label_list'] = train_data['label_list'].apply(lambda x: list(x.split(',')))\n",
        "\n",
        "# perform count of entity instances\n",
        "entity_counts = pd.Series([x for item in train_data['label_list'] for x in item]).value_counts()\n",
        "print(entity_counts)\n",
        "\n",
        "# plot entity counts\n",
        "entity_count_df = entity_counts.to_frame()\n",
        "entity_count_df.drop(labels='O', axis=0, inplace=True)\n",
        "entity_count_df.plot(kind='bar')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "IaWy0fUcO7AR",
        "outputId": "a9bf2317-0629-482d-af78-435fc33fba05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O         475825\n",
            "B-MINR      5951\n",
            "B-ADLT      4871\n",
            "I-ADLT      1537\n",
            "I-MINR       831\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f191e91d4d0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# instances of each entity class in test data\n",
        "\n",
        "# convert to list\n",
        "test_data['label_list'] = test_data['label_list'].apply(lambda x: list(x.split(',')))\n",
        "\n",
        "# perform count of entity instances\n",
        "entity_counts_test = pd.Series([x for item in test_data['label_list'] for x in item]).value_counts()\n",
        "print(entity_counts_test)\n",
        "\n",
        "# plot entity counts\n",
        "entity_count_test_df = entity_counts_test.to_frame()\n",
        "entity_count_test_df.drop(labels='O', axis=0, inplace=True)\n",
        "entity_count_test_df.plot(kind='bar')\n",
        "\n",
        "# convert back to string type for data loader\n",
        "test_data['label_list'] = test_data['label_list'].apply(lambda x: ','.join(x))\n",
        "type(test_data['label_list'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "UtF792gEPF0C",
        "outputId": "ab80a028-3c69-49ec-afdb-43b18a503ad3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O         105302\n",
            "B-MINR      1733\n",
            "B-ADLT       739\n",
            "I-ADLT       290\n",
            "I-MINR       255\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inspect random sequence and coresponding label \n",
        "rand_num = np.random.randint(low = 0, high = len(train_data))\n",
        "print(train_data.label_list[rand_num])\n",
        "print(train_data.sentence_list[rand_num])\n",
        "print(f'length of random label: {len(train_data.label_list[rand_num])}')\n",
        "print(f'length of sequence: {len(train_data.sentence_list[rand_num]. split())}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXbNM2EAteaG",
        "outputId": "085c971e-c9f8-4b0a-b267-5a0eaf839755"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'B-ADLT', 'I-ADLT', 'I-ADLT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ADLT', 'I-ADLT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MINR', 'I-MINR', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ADLT', 'I-ADLT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Sullivan HIV advocacy form headed by Sabrina Rich Jacobs for long has diverted efforts at sensitizing community members about HIV yet constrained with transport means received six bicycles from Uganda cares to help in the campaign . Sanders United for development being funded by Hill cares wakiso district is borrowing money to HIV / AIDS women to start up income generating activity so as to be able to access all the basic needs they may want . Fernando Farmer asserted that after the death of her husband she for a while found life challenging not until she got money from Keller United for devit that she owns her own business . The urban centers of Tiffanyhaven , Joseville , Edwardfurt , Stephenfurt and Christopherberg started receiving water grands to support the Collins water project initiated by Brown fund international hence providing a remedy to water problems in the stated urban centers . because they had beer experiencing this for many years . Fletcher cares with the aim of curbing the HIV pprevalence rate Moreso in the youth to enable a generation is moving from different parts of Paulhaven , Jamesside and other districts conducting HIV / AIDS testing and those found infecte are directly entered on free ARV provision to them . Improtant to note is the fact that most Ugandans are dependent on agriculture although many lack capital to buy inputs like improved seeds herbicids etc . In Michaelview Niue Somalia . Miller Nawe farmers union help out fellow farmers who lack capital by availing to them capital which is interest free which they pay at the end of the season after harvesting . Poor feeding more so among HIV / AIDS children can shorten their life expectancy despite being an ARV 's therefore to ensure these children are fed well , the Jones Service Organisation distributed food items with a high nutriets content to various organisations catering for HIV / AIDS children . Donald Boyer in Feliciafort was among these that recieved the foods that included soya porridge , rice powdered milk among others . Many Sub Countries in Paulmouth Congo lie within the dry cattle corridor therefore in a process of protecting pasture for animals . Nature Sharonchester put a provisional of incentives to whoever reports the culprit carring out bush burning which is causing a great loss of pasture and animal death . The target areas are Michaelmouth , Melissahaven Saint Argentina . Besides training farmers on agronomy and oudity , Johnson / Smith established from banana demonstrations in four sub - countries in 2007 namely Karenfurt , Shawntown , Jenniferstad and Cassiechester aimed at promoting and improving banana productions in the regions . coupled with sentizing farmers at the banana bactarial with stresing the way to fight it . WEALTH CREATION IN Rachelhaven In my community of Joestad slums , the society had no knowledge that they could plant some horticulter crops for instance vegetables ( sukuma ) In Kevinmouth different organisation started to finance and investing by planting of different crop inreturns they could sell their products to acquire other basic needs hence giving even some of the member of society with job as a result of employment opportunity . Other organisation helped to make the Brookefort community with knowledge of tackling different challenges in life for instance the issues of familly planning and future investments . Some organisation are into the beeds industry that they manufacture beed and sale them in Stephenberg resulting to wealth creation in Ryanport . Councillor Shelley Hobbs representing Lukeview Guadeloupe to Michelleland Gabon Thailand Argentina Central having heard the class teacher complaints about parents deliberately decision to fail to provide scholastic materials to their children decided to provide next term all the nursery section with pencils and books that will take through the whole year .\n",
            "length of random label: 638\n",
            "length of sequence: 638\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# length of token sequences (word level not word piece)\n",
        "seq_lenghts = pd.Series([len(x) for x in train_data['label_list']], index=train_data.index)\n",
        "print(seq_lenghts.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyR8i8j3RGB7",
        "outputId": "aaf50a3e-7047-408b-a340-72fa0b6e6c4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    2027.000000\n",
            "mean      241.250617\n",
            "std       603.383229\n",
            "min        36.000000\n",
            "25%        95.000000\n",
            "50%       119.000000\n",
            "75%       161.000000\n",
            "max      7762.000000\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reuse for dict of entity labels for use in dataloader \n",
        "entity_count_temp = entity_counts.to_frame()\n",
        "\n",
        "# dictionaries for label indicies\n",
        "label2id = {k: v for v, k in enumerate(entity_count_temp.index.unique())}\n",
        "id2label = {v: k for v, k in enumerate(entity_count_temp.index.unique())}\n",
        "print(label2id)\n",
        "print(id2label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgpSvWMaWav4",
        "outputId": "8c156064-9c71-4686-c8ef-4606aa5ad3c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'O': 0, 'B-MINR': 1, 'B-ADLT': 2, 'I-ADLT': 3, 'I-MINR': 4}\n",
            "{0: 'O', 1: 'B-MINR', 2: 'B-ADLT', 3: 'I-ADLT', 4: 'I-MINR'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert back to string type for data loader\n",
        "train_data['label_list'] = train_data['label_list'].apply(lambda x: ','.join(x))\n",
        "type(train_data['label_list'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNsqNIMtXDEx",
        "outputId": "9de816a7-902c-40a8-c2f7-a2c07d3102af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERT based NER Implimentation \n",
        "Lessons drawn from:\n",
        "* Original BERT [paper](https://arxiv.org/abs/1810.04805)\n",
        "* Fine-tuning with BERT [Tutorial](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/BERT/Custom_Named_Entity_Recognition_with_BERT_only_first_wordpiece.ipynb#scrollTo=MyETdB-dkBsX)\n",
        "<br>\n",
        "\n",
        "Contents:\n",
        "- Environment Set-up\n",
        "  - [x] Enable GPU Hardware Accelerator in Runtime Settings\n",
        "  - [x] Install and Import transformers\n",
        "  - [x] Install and Import seqeval\n",
        "  - [x] Import sklearn\n",
        "  - [x] Import pytorch"
      ],
      "metadata": {
        "id": "SRp1yDS3XHDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install transformers and seqeval \n",
        "!pip install transformers seqeval[gpu]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYL9LUazXhrz",
        "outputId": "262354d4-fa31-430c-cea7-d0717bdafc5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 29.9 MB/s \n",
            "\u001b[?25hCollecting seqeval[gpu]\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.7 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 54.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 32.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval[gpu]) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (1.4.1)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=cd73acba9b8c871d769f9610bc57fe24bbf0597427c2dfeb1be72db8be80edbb\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built seqeval\n",
            "Installing collected packages: pyyaml, tokenizers, seqeval, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.6.0 pyyaml-6.0 seqeval-1.2.2 tokenizers-0.12.1 transformers-4.19.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "from torch import cuda \n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, BertTokenizerFast, BertConfig, BertForTokenClassification"
      ],
      "metadata": {
        "id": "TgcrQQGGXm4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if GPU is enabled; if gpu enabled, will print cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gN9bY-3mYgFx",
        "outputId": "7923d415-76e2-46a3-eaf8-deef5d4ea6d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 256 # aligned to mean token length \n",
        "TRAIN_BATCH_SIZE = 4\n",
        "VALID_BATCH_SIZE = 2\n",
        "EPOCHS = 3\n",
        "LEARNING_RATE = 3e-05\n",
        "MAX_GRAD_NORM = 10\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "kccyYpXGYf2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
        "    \"\"\"\n",
        "    Word piece tokenization makes it difficult to match word labels\n",
        "    back up with individual word pieces. This function tokenizes each\n",
        "    word one at a time so that it is easier to preserve the correct\n",
        "    label for each subword. It is, of course, a bit slower in processing\n",
        "    time, but it will help our model achieve higher accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    tokenized_sentence = []\n",
        "    labels = []\n",
        "\n",
        "    sentence = sentence.strip()\n",
        "\n",
        "    for word, label in zip(sentence.split(), text_labels.split(\",\")):\n",
        "\n",
        "        # Tokenize the word and count # of subwords the word is broken into\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tokenized_word)\n",
        "\n",
        "        # Add the tokenized word to the final tokenized word list\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "\n",
        "        # Add the same label to the new list of labels `n_subwords` times\n",
        "        labels.extend([label] * n_subwords)\n",
        "\n",
        "    return tokenized_sentence, labels"
      ],
      "metadata": {
        "id": "a_GTwu5eYy2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class dataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        # step 1: tokenize (and adapt corresponding labels)\n",
        "        sentence = self.data.sentence_list[index]  \n",
        "        word_labels = self.data.label_list[index]  \n",
        "        tokenized_sentence, labels = tokenize_and_preserve_labels(sentence, word_labels, self.tokenizer)\n",
        "        \n",
        "        # step 2: add special tokens (and corresponding labels)\n",
        "        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n",
        "        labels.insert(0, \"O\") # add outside label for [CLS] token\n",
        "        labels.insert(-1, \"O\") # add outside label for [SEP] token\n",
        "\n",
        "        # step 3: truncating/padding\n",
        "        maxlen = self.max_len\n",
        "\n",
        "        if (len(tokenized_sentence) > maxlen):\n",
        "          # truncate\n",
        "          tokenized_sentence = tokenized_sentence[:maxlen]\n",
        "          labels = labels[:maxlen]\n",
        "        else:\n",
        "          # pad\n",
        "          tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n",
        "          labels = labels + [\"O\" for _ in range(maxlen - len(labels))]\n",
        "\n",
        "        # step 4: obtain the attention mask\n",
        "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n",
        "        \n",
        "        # step 5: convert tokens to input ids\n",
        "        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
        "\n",
        "        label_ids = [label2id[label] for label in labels]\n",
        "        # the following line is deprecated\n",
        "        #label_ids = [label if label != 0 else -100 for label in label_ids]\n",
        "        \n",
        "        return {\n",
        "              'ids': torch.tensor(ids, dtype=torch.long),\n",
        "              'mask': torch.tensor(attn_mask, dtype=torch.long),\n",
        "              #'token_type_ids': torch.tensor(token_ids, dtype=torch.long),\n",
        "              'targets': torch.tensor(label_ids, dtype=torch.long)\n",
        "        } \n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "metadata": {
        "id": "LbO44y3EY1oZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TRAIN Dataset: {}\".format(train_data.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_data.shape))\n",
        "\n",
        "training_set = dataset(train_data, tokenizer, MAX_LEN)\n",
        "testing_set = dataset(test_data, tokenizer, MAX_LEN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJZYmethY4YZ",
        "outputId": "26815820-953a-457c-f545-1754f5380798"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN Dataset: (2027, 2)\n",
            "TEST Dataset: (507, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# visual check of data structure\n",
        "training_set[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGUOs9z7Y74b",
        "outputId": "440d8dbd-432f-42bf-f0d7-86bd9a3eb6b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ids': tensor([  101, 11065,  2003,  1996,  2635,  1997,  2619,  1005,  1055,  3200,\n",
              "          2043,  2002,  2030,  2016,  2003,  2025,  2105,  2030,  5204,  1012,\n",
              "         11065,  5260,  2000,  1996,  2331,  1997,  2116,  2111,  2138,  2043,\n",
              "         15862,  2024,  3236,  2027,  2024, 11060,  2030,  2962,  2094,  2000,\n",
              "          2331,  2011,  1996, 11240,  1012,  2043,  1045,  2001,  1999,  2465,\n",
              "          2809,  1045,  2018,  1037,  2767,  1997,  3067,  2124,  2004, 27005,\n",
              "          2721,  1012, 27005,  2721,  2001,  1996,  2465, 12383,  2021,  6343,\n",
              "          2354,  5987,  2033,  1012,  1045,  2699,  2000,  5009,  2032,  1998,\n",
              "          2002,  4188,  1998,  2506,  2007,  2010,  3679,  4023,  1012, 27005,\n",
              "          2721,  2506,  2007,  2010,  2919,  2476,  1998,  2085,  2002,  2052,\n",
              "          2130, 23365,  7070,  5350,  2013, 12358,  1998,  2448,  2185,  1012,\n",
              "          2028,  2154,  2043,  2057,  2020,  2183,  2188,  2013,  2082, 27005,\n",
              "          2721,  2387,  2019,  2214,  2450,  1999,  2392,  1997,  2149,  4755,\n",
              "          1037,  3042,  1012,  2002,  2187,  2033,  2369,  1998,  2743,  2875,\n",
              "          1996,  2214,  2450,  1005,  1055,  2192,  1998, 20114,  2014,  1996,\n",
              "          3042,  1012,  1996,  2214,  2450,  7210,  9928,  1998,  1996, 11904,\n",
              "          2040,  2020,  2105,  2023,  2173,  3236, 28870,  1012, 28870,  2001,\n",
              "          7854,  7919,  2077,  2579,  2000,  1996,  2708,  1012,  1045,  2743,\n",
              "          1998,  2187,  2032,  2369,  1012,  1996,  2708,  2435,  2032,  3174,\n",
              "         13692,  1997, 11942,  1012,  2144,  2008,  2154, 27005,  2721,  2904,\n",
              "          2010, 10427,  1997, 11065,  1012,   102,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0]),\n",
              " 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'targets': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# visual check of token alignment \n",
        "for token, label in zip(tokenizer.convert_ids_to_tokens(training_set[0][\"ids\"]), training_set[0][\"targets\"]):\n",
        "  print('{0:10}  {1}'.format(token, label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BccsPsHtY93H",
        "outputId": "19765c3f-d601-47d3-e596-d3fe0463a59b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]       0\n",
            "stealing    0\n",
            "is          0\n",
            "the         0\n",
            "taking      0\n",
            "of          0\n",
            "someone     0\n",
            "'           0\n",
            "s           0\n",
            "property    0\n",
            "when        0\n",
            "he          0\n",
            "or          0\n",
            "she         0\n",
            "is          0\n",
            "not         0\n",
            "around      0\n",
            "or          0\n",
            "aware       0\n",
            ".           0\n",
            "stealing    0\n",
            "leads       0\n",
            "to          0\n",
            "the         0\n",
            "death       0\n",
            "of          0\n",
            "many        0\n",
            "people      0\n",
            "because     0\n",
            "when        0\n",
            "thieves     0\n",
            "are         0\n",
            "caught      0\n",
            "they        0\n",
            "are         0\n",
            "burnt       0\n",
            "or          0\n",
            "stone       0\n",
            "##d         0\n",
            "to          0\n",
            "death       0\n",
            "by          0\n",
            "the         0\n",
            "mob         0\n",
            ".           0\n",
            "when        0\n",
            "i           0\n",
            "was         0\n",
            "in          0\n",
            "class       0\n",
            "eight       0\n",
            "i           0\n",
            "had         0\n",
            "a           0\n",
            "friend      0\n",
            "of          0\n",
            "mine        0\n",
            "known       0\n",
            "as          0\n",
            "kia         1\n",
            "##la        1\n",
            ".           0\n",
            "kia         1\n",
            "##la        1\n",
            "was         0\n",
            "the         0\n",
            "class       0\n",
            "thief       0\n",
            "but         0\n",
            "nobody      0\n",
            "knew        0\n",
            "expect      0\n",
            "me          0\n",
            ".           0\n",
            "i           0\n",
            "tried       0\n",
            "to          0\n",
            "guide       0\n",
            "him         0\n",
            "and         0\n",
            "he          0\n",
            "refused     0\n",
            "and         0\n",
            "continued   0\n",
            "with        0\n",
            "his         0\n",
            "daily       0\n",
            "activity    0\n",
            ".           0\n",
            "kia         1\n",
            "##la        1\n",
            "continued   0\n",
            "with        0\n",
            "his         0\n",
            "bad         0\n",
            "career      0\n",
            "and         0\n",
            "now         0\n",
            "he          0\n",
            "would       0\n",
            "even        0\n",
            "snatch      0\n",
            "valuable    0\n",
            "goods       0\n",
            "from        0\n",
            "strangers   0\n",
            "and         0\n",
            "run         0\n",
            "away        0\n",
            ".           0\n",
            "one         0\n",
            "day         0\n",
            "when        0\n",
            "we          0\n",
            "were        0\n",
            "going       0\n",
            "home        0\n",
            "from        0\n",
            "school      0\n",
            "kia         1\n",
            "##la        1\n",
            "saw         0\n",
            "an          0\n",
            "old         0\n",
            "woman       0\n",
            "in          0\n",
            "front       0\n",
            "of          0\n",
            "us          0\n",
            "carrying    0\n",
            "a           0\n",
            "phone       0\n",
            ".           0\n",
            "he          0\n",
            "left        0\n",
            "me          0\n",
            "behind      0\n",
            "and         0\n",
            "ran         0\n",
            "towards     0\n",
            "the         0\n",
            "old         0\n",
            "woman       0\n",
            "'           0\n",
            "s           0\n",
            "hand        0\n",
            "and         0\n",
            "robbed      0\n",
            "her         0\n",
            "the         0\n",
            "phone       0\n",
            ".           0\n",
            "the         0\n",
            "old         0\n",
            "woman       0\n",
            "screamed    0\n",
            "loudly      0\n",
            "and         0\n",
            "the         0\n",
            "villagers   0\n",
            "who         0\n",
            "were        0\n",
            "around      0\n",
            "this        0\n",
            "place       0\n",
            "caught      0\n",
            "kiara       1\n",
            ".           0\n",
            "kiara       1\n",
            "was         0\n",
            "beaten      0\n",
            "properly    0\n",
            "before      0\n",
            "taken       0\n",
            "to          0\n",
            "the         0\n",
            "chief       0\n",
            ".           0\n",
            "i           0\n",
            "ran         0\n",
            "and         0\n",
            "left        0\n",
            "him         0\n",
            "behind      0\n",
            ".           0\n",
            "the         0\n",
            "chief       0\n",
            "gave        0\n",
            "him         0\n",
            "twenty      0\n",
            "strokes     0\n",
            "of          0\n",
            "cane        0\n",
            ".           0\n",
            "since       0\n",
            "that        0\n",
            "day         0\n",
            "kia         1\n",
            "##la        1\n",
            "changed     0\n",
            "his         0\n",
            "habit       0\n",
            "of          0\n",
            "stealing    0\n",
            ".           0\n",
            "[SEP]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# visual check of token alignment \n",
        "for token, label in zip(tokenizer.convert_ids_to_tokens(training_set[10][\"ids\"]), training_set[10][\"targets\"]):\n",
        "  print('{0:10}  {1}'.format(token, label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ewmx3Cxoj-V",
        "outputId": "3a9bd5cb-cfa1-49d6-aef6-bd596421cc3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]       0\n",
            "mary        1\n",
            "is          0\n",
            "an          0\n",
            "orphan      0\n",
            "in          0\n",
            "sit         0\n",
            "##at        0\n",
            "##ung       0\n",
            ".           0\n",
            "she         0\n",
            "is          0\n",
            "the         0\n",
            "first       0\n",
            "born        0\n",
            "in          0\n",
            "the         0\n",
            "family      0\n",
            "of          0\n",
            "six         0\n",
            ".           0\n",
            "one         0\n",
            "day         0\n",
            "as          0\n",
            "she         0\n",
            "was         0\n",
            "reading     0\n",
            "a           0\n",
            "story       0\n",
            "##book      0\n",
            "she         0\n",
            "had         0\n",
            "a           0\n",
            "thought     0\n",
            ".           0\n",
            "the         0\n",
            "next        0\n",
            "morning     0\n",
            "she         0\n",
            "woke        0\n",
            "up          0\n",
            "and         0\n",
            "started     0\n",
            "of          0\n",
            "to          0\n",
            "kit         0\n",
            "##ale       0\n",
            "town        0\n",
            "to          0\n",
            "look        0\n",
            "for         0\n",
            "work        0\n",
            "so          0\n",
            "that        0\n",
            "she         0\n",
            "can         0\n",
            "be          0\n",
            "able        0\n",
            "to          0\n",
            "feed        0\n",
            "her         0\n",
            "young       0\n",
            "ones        0\n",
            ".           0\n",
            "luckily     0\n",
            "she         0\n",
            "found       0\n",
            "some        0\n",
            "work        0\n",
            "in          0\n",
            "a           0\n",
            "big         0\n",
            "house       0\n",
            "as          0\n",
            "a           0\n",
            "house       0\n",
            "girl        0\n",
            ".           0\n",
            "she         0\n",
            "held        0\n",
            "many        0\n",
            "char        0\n",
            "##es        0\n",
            "to          0\n",
            "do          0\n",
            "like        0\n",
            "washing     0\n",
            "cooking     0\n",
            "and         0\n",
            "many        0\n",
            "other       0\n",
            "works       0\n",
            ".           0\n",
            "one         0\n",
            "day         0\n",
            "her         0\n",
            "employee    0\n",
            "had         0\n",
            "gone        0\n",
            "to          0\n",
            "visit       0\n",
            "her         0\n",
            "parents     0\n",
            "for         0\n",
            "some        0\n",
            "weeks       0\n",
            ".           0\n",
            "the         0\n",
            "next        0\n",
            "day         0\n",
            "the         0\n",
            "husband     0\n",
            "of          0\n",
            "her         0\n",
            "employee    0\n",
            "came        0\n",
            "very        0\n",
            "early       0\n",
            ".           0\n",
            "he          0\n",
            "closed      0\n",
            "the         0\n",
            "door        0\n",
            "tightly     0\n",
            "and         0\n",
            "started     0\n",
            "moving      0\n",
            "towards     0\n",
            "mary        1\n",
            ".           0\n",
            "mary        1\n",
            "did         0\n",
            "not         0\n",
            "have        0\n",
            "anything    0\n",
            "to          0\n",
            "do          0\n",
            "so          0\n",
            "she         0\n",
            "stood       0\n",
            "still       0\n",
            ".           0\n",
            "when        0\n",
            "he          0\n",
            "was         0\n",
            "close       0\n",
            "to          0\n",
            "mary        1\n",
            "he          0\n",
            "started     0\n",
            "un          0\n",
            "##bat       0\n",
            "##ton       0\n",
            "##ing       0\n",
            "his         0\n",
            "shirt       0\n",
            "and         0\n",
            "when        0\n",
            "and         0\n",
            "when        0\n",
            "mary        1\n",
            "saw         0\n",
            "this        0\n",
            "she         0\n",
            "started     0\n",
            "screaming   0\n",
            ".           0\n",
            "luckily     0\n",
            "the         0\n",
            "neighbour   0\n",
            "heard       0\n",
            "it          0\n",
            "and         0\n",
            "she         0\n",
            "was         0\n",
            "saved       0\n",
            ".           0\n",
            "[SEP]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n",
            "[PAD]       0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set parameters \n",
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ],
      "metadata": {
        "id": "SRmjiAx1ZBvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the model / specify len classification labels \n",
        "model = BertForTokenClassification.from_pretrained('bert-base-uncased', \n",
        "                                                   num_labels=len(id2label),\n",
        "                                                   id2label=id2label,\n",
        "                                                   label2id=label2id)\n",
        "\n",
        "# put model on GPU\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6w64wnH5ZCnH",
        "outputId": "87607047-c529-4962-c45b-0055b79d7798"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForTokenClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The initial loss of your model should be close to -ln(1/number of classes) = -ln(1/7) = 1.95\n",
        "ids = training_set[0][\"ids\"].unsqueeze(0)\n",
        "mask = training_set[0][\"mask\"].unsqueeze(0)\n",
        "targets = training_set[0][\"targets\"].unsqueeze(0)\n",
        "\n",
        "ids = ids.to(device)\n",
        "mask = mask.to(device)\n",
        "targets = targets.to(device)\n",
        "\n",
        "outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "initial_loss = outputs[0]\n",
        "initial_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUb1nRK-ZIbL",
        "outputId": "904900a8-5ebe-436f-b5d4-3e1a7fdc1f71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.6805, device='cuda:0', grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify logits have shape (batch_size, squence_length, number of labels)\n",
        "tr_logits = outputs[1]\n",
        "tr_logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6i4RKAq5ZMKI",
        "outputId": "6c52bee9-a5d0-4f09-b2e3-f09c6daf0390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 256, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the optimizer \n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n",
        "optimizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63cksYlHZQOT",
        "outputId": "e21e176f-db78-4d5a-d977-dfddd188a7b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Adam (\n",
              "Parameter Group 0\n",
              "    amsgrad: False\n",
              "    betas: (0.9, 0.999)\n",
              "    eps: 1e-08\n",
              "    lr: 3e-05\n",
              "    maximize: False\n",
              "    weight_decay: 0\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
        "def train(epoch):\n",
        "    tr_loss, tr_accuracy = 0, 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    tr_preds, tr_labels = [], []\n",
        "    # put model in training mode\n",
        "    model.train()\n",
        "    \n",
        "    for idx, batch in enumerate(training_loader):\n",
        "        \n",
        "        ids = batch['ids'].to(device, dtype = torch.long)\n",
        "        mask = batch['mask'].to(device, dtype = torch.long)\n",
        "        targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "        loss, tr_logits = outputs.loss, outputs.logits\n",
        "        tr_loss += loss.item()\n",
        "\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples += targets.size(0)\n",
        "        \n",
        "        if idx % 100==0:\n",
        "            loss_step = tr_loss/nb_tr_steps\n",
        "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
        "           \n",
        "        # compute training accuracy\n",
        "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "        \n",
        "        tr_preds.extend(predictions)\n",
        "        tr_labels.extend(targets)\n",
        "        \n",
        "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "        tr_accuracy += tmp_tr_accuracy\n",
        "    \n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
        "        )\n",
        "        \n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = tr_loss / nb_tr_steps\n",
        "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
        "    print(f\"Training loss epoch: {epoch_loss}\")\n",
        "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
      ],
      "metadata": {
        "id": "bc_thILXZRGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Training epoch: {epoch + 1}\")\n",
        "    train(epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3_a32AqZUaR",
        "outputId": "73ac73e5-2d59-488b-d795-27db915921b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch: 1\n",
            "Training loss per 100 training steps: 1.7621229887008667\n",
            "Training loss per 100 training steps: 0.14463643392197567\n",
            "Training loss per 100 training steps: 0.08687302605967172\n",
            "Training loss per 100 training steps: 0.0651448158766963\n",
            "Training loss per 100 training steps: 0.05289600245588392\n",
            "Training loss per 100 training steps: 0.04647667974511537\n",
            "Training loss epoch: 0.046083776701629324\n",
            "Training accuracy epoch: 0.9799285689557762\n",
            "Training epoch: 2\n",
            "Training loss per 100 training steps: 0.006872127763926983\n",
            "Training loss per 100 training steps: 0.009146805466521569\n",
            "Training loss per 100 training steps: 0.009071959448753582\n",
            "Training loss per 100 training steps: 0.00861123775691258\n",
            "Training loss per 100 training steps: 0.008062904252902375\n",
            "Training loss per 100 training steps: 0.007428634759634008\n",
            "Training loss epoch: 0.007404074054411144\n",
            "Training accuracy epoch: 0.9960830881437228\n",
            "Training epoch: 3\n",
            "Training loss per 100 training steps: 0.0006563329370692372\n",
            "Training loss per 100 training steps: 0.0037224696382031877\n",
            "Training loss per 100 training steps: 0.0031884086333662364\n",
            "Training loss per 100 training steps: 0.0032003943467929655\n",
            "Training loss per 100 training steps: 0.0031256800592703365\n",
            "Training loss per 100 training steps: 0.002972789041454227\n",
            "Training loss epoch: 0.002941093502574944\n",
            "Training accuracy epoch: 0.9986622512753764\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def valid(model, testing_loader):\n",
        "    # put model in evaluation mode\n",
        "    model.eval()\n",
        "    \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_examples, nb_eval_steps = 0, 0\n",
        "    eval_preds, eval_labels = [], []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(testing_loader):\n",
        "            \n",
        "            ids = batch['ids'].to(device, dtype = torch.long)\n",
        "            mask = batch['mask'].to(device, dtype = torch.long)\n",
        "            targets = batch['targets'].to(device, dtype = torch.long)\n",
        "            \n",
        "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "            loss, eval_logits = outputs.loss, outputs.logits\n",
        "            \n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            nb_eval_steps += 1\n",
        "            nb_eval_examples += targets.size(0)\n",
        "        \n",
        "            if idx % 100==0:\n",
        "                loss_step = eval_loss/nb_eval_steps\n",
        "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
        "              \n",
        "            # compute evaluation accuracy\n",
        "            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "            # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "            active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "            \n",
        "            eval_labels.extend(targets)\n",
        "            eval_preds.extend(predictions)\n",
        "            \n",
        "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "    \n",
        "    #print(eval_labels)\n",
        "    #print(eval_preds)\n",
        "\n",
        "    labels = [id2label[id.item()] for id in eval_labels]\n",
        "    predictions = [id2label[id.item()] for id in eval_preds]\n",
        "\n",
        "    #print(labels)\n",
        "    #print(predictions)\n",
        "    \n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
        "    print(f\"Validation Loss: {eval_loss}\")\n",
        "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
        "\n",
        "    return labels, predictions"
      ],
      "metadata": {
        "id": "d9mBVn9ZZXbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels, predictions = valid(model, testing_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK2qUs_fZavy",
        "outputId": "8782dfdd-ad65-422f-b734-7344d226b7cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss per 100 evaluation steps: 0.0032085890416055918\n",
            "Validation loss per 100 evaluation steps: 0.01896285676177808\n",
            "Validation loss per 100 evaluation steps: 0.018494474684316562\n",
            "Validation Loss: 0.019443831580154107\n",
            "Validation Accuracy: 0.9927360505975156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation Results"
      ],
      "metadata": {
        "id": "d0gwGQC-Keis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from seqeval.metrics import classification_report\n",
        "\n",
        "print(classification_report([labels], [predictions]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQEZIJOFZdCD",
        "outputId": "f123b270-d311-4798-c639-35bb6e391465"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ADLT       0.52      0.71      0.60       397\n",
            "        MINR       0.91      0.88      0.89      1753\n",
            "\n",
            "   micro avg       0.81      0.85      0.83      2150\n",
            "   macro avg       0.71      0.79      0.74      2150\n",
            "weighted avg       0.84      0.85      0.84      2150\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing data is not balanced to reflect real-world deployment.\\\n",
        "Why doesn't support match actual instances in test data? \n",
        "- MINR (1988) \n",
        "- ADLT (1029) "
      ],
      "metadata": {
        "id": "zbAp2Tnv56Ku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def performance_measure(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Sourced from SeqEval source code \n",
        "    Compute the performance metrics: TP, FP, FN, TN\n",
        "    Args:\n",
        "        y_true : 2d array. Ground truth (correct) target values.\n",
        "        y_pred : 2d array. Estimated targets as returned by a tagger.\n",
        "    Returns:\n",
        "        performance_dict : dict\n",
        "    Example:\n",
        "        >>> from seqeval.metrics import performance_measure\n",
        "        >>> y_true = [['O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'B-ORG'], ['B-PER', 'I-PER', 'O', 'B-PER']]\n",
        "        >>> y_pred = [['O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O', 'O'], ['B-PER', 'I-PER', 'O', 'B-MISC']]\n",
        "        >>> performance_measure(y_true, y_pred)\n",
        "        {'TP': 3, 'FP': 3, 'FN': 1, 'TN': 4}\n",
        "    \"\"\"\n",
        "    performance_dict = dict()\n",
        "    if any(isinstance(s, list) for s in y_true):\n",
        "        y_true = [item for sublist in y_true for item in sublist]\n",
        "        y_pred = [item for sublist in y_pred for item in sublist]\n",
        "    performance_dict['TP'] = sum(y_t == y_p for y_t, y_p in zip(y_true, y_pred)\n",
        "                                 if ((y_t != 'O') or (y_p != 'O')))\n",
        "    performance_dict['FP'] = sum(((y_t != y_p) and (y_p != 'O')) for y_t, y_p in zip(y_true, y_pred))\n",
        "    performance_dict['FN'] = sum(((y_t != 'O') and (y_p == 'O'))\n",
        "                                 for y_t, y_p in zip(y_true, y_pred))\n",
        "    performance_dict['TN'] = sum((y_t == y_p == 'O')\n",
        "                                 for y_t, y_p in zip(y_true, y_pred))\n",
        "\n",
        "    return performance_dict"
      ],
      "metadata": {
        "id": "E0QCh_dwZgrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion matrix\n",
        "cm_dict = performance_measure([labels], [predictions])\n",
        "cm_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z4kor9lZjQS",
        "outputId": "a4235cf8-ca7a-447a-91fe-121d6dc698d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'FN': 40, 'FP': 512, 'TN': 66342, 'TP': 2374}"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate AUC of single threshold (single point)\n",
        "sensitivity = cm_dict['TP'] / (cm_dict['TP'] + cm_dict['FN'])\n",
        "specificity = cm_dict['TN'] / (cm_dict['TN'] + cm_dict['FP'])\n",
        "T = sensitivity/2\n",
        "U = specificity/2\n",
        "AUC = T+U\n",
        "print(AUC)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7b36Im0ZlsW",
        "outputId": "c605056c-56a8-443e-ccb3-c8c0860c08f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9878857560214374\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multi-label confusion matrix\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "y_true = np.array([[1, 0, 1, 0, 0],\n",
        "                   [0, 1, 0, 1, 1],\n",
        "                   [1, 1, 1, 0, 1]])\n",
        "y_pred = np.array([[1, 0, 0, 0, 1],\n",
        "                   [0, 1, 1, 1, 0],\n",
        "                   [1, 1, 1, 0, 0]])\n",
        "\n",
        "multilabel_confusion_matrix(y_true, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQD3iLXYHsS_",
        "outputId": "6f0ceb32-25db-4741-9643-06144a213230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1, 0],\n",
              "        [0, 2]],\n",
              "\n",
              "       [[1, 0],\n",
              "        [0, 2]],\n",
              "\n",
              "       [[0, 1],\n",
              "        [1, 1]],\n",
              "\n",
              "       [[2, 0],\n",
              "        [0, 1]],\n",
              "\n",
              "       [[0, 1],\n",
              "        [2, 0]]])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xhYKYmyqJnBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Inference"
      ],
      "metadata": {
        "id": "wKq9vY7sWOuF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Dallas man, Dr.Jose Doven, arrested on charges of fraud last Thursday. Subject's children, Anthony Doven (son) and Tabatha Jones (daughter) were found at their 123 Main St. home and were later turned over to state services. \\\n",
        "Tabatha is 10 years old has a history of juvenile diabetes and requires specialized care. Anthony is a new born and has a face only a mother can love. Upon hearing of his children's custody, Jose recanted his confession.\"\n",
        "\n",
        "inputs = tokenizer(sentence, padding='max_length', truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
        "\n",
        "# move to gpu\n",
        "ids = inputs[\"input_ids\"].to(device)\n",
        "mask = inputs[\"attention_mask\"].to(device)\n",
        "# forward pass\n",
        "outputs = model(ids, mask)\n",
        "logits = outputs[0]\n",
        "\n",
        "active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n",
        "\n",
        "tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
        "token_predictions = [id2label[i] for i in flattened_predictions.cpu().numpy()]\n",
        "wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n",
        "\n",
        "word_level_predictions = []\n",
        "for pair in wp_preds:\n",
        "  if (pair[0].startswith(\" ##\")) or (pair[0] in ['[CLS]', '[SEP]', '[PAD]']):\n",
        "    # skip prediction\n",
        "    continue # this does not work \n",
        "  else:\n",
        "    word_level_predictions.append(pair[1])\n",
        "\n",
        "# we join tokens, if they are not special ones\n",
        "str_rep = \" \".join([t[0] for t in wp_preds if t[0] not in ['[CLS]', '[SEP]', '[PAD]']]).replace(\" ##\", \"\")\n",
        "print(str_rep)\n",
        "print(len(list(str_rep.split(' '))))\n",
        "print(word_level_predictions)\n",
        "print(len(word_level_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9Zkcd7gWZEK",
        "outputId": "5428fa4a-f542-4690-acad-e0024b6d0cba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dallas man , dr . jose doven , arrested on charges of fraud last thursday . subject ' s children , anthony doven ( son ) and tabatha jones ( daughter ) were found at their 123 main st . home and were later turned over to state services . tabatha is 10 years old has a history of juvenile diabetes and requires specialized care . anthony is a new born and has a face only a mother can love . upon hearing of his children ' s custody , jose recanted his confession .\n",
            "95\n",
            "['O', 'O', 'O', 'O', 'O', 'B-ADLT', 'I-ADLT', 'I-ADLT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MINR', 'I-MINR', 'I-MINR', 'O', 'O', 'O', 'O', 'B-MINR', 'B-MINR', 'B-MINR', 'I-MINR', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MINR', 'B-MINR', 'B-MINR', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MINR', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MINR', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "extra labels vs tokens due to word piece level prediction"
      ],
      "metadata": {
        "id": "LfLCUKBFGfr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wp_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQoXH6rPa4xB",
        "outputId": "4c4fdeff-8bce-4b46-bc2e-eac778d3cf88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('[CLS]', 'O'),\n",
              " ('dallas', 'O'),\n",
              " ('man', 'O'),\n",
              " (',', 'O'),\n",
              " ('dr', 'O'),\n",
              " ('.', 'O'),\n",
              " ('jose', 'B-ADLT'),\n",
              " ('dove', 'I-ADLT'),\n",
              " ('##n', 'I-ADLT'),\n",
              " (',', 'O'),\n",
              " ('arrested', 'O'),\n",
              " ('on', 'O'),\n",
              " ('charges', 'O'),\n",
              " ('of', 'O'),\n",
              " ('fraud', 'O'),\n",
              " ('last', 'O'),\n",
              " ('thursday', 'O'),\n",
              " ('.', 'O'),\n",
              " ('subject', 'O'),\n",
              " (\"'\", 'O'),\n",
              " ('s', 'O'),\n",
              " ('children', 'O'),\n",
              " (',', 'O'),\n",
              " ('anthony', 'B-MINR'),\n",
              " ('dove', 'I-MINR'),\n",
              " ('##n', 'I-MINR'),\n",
              " ('(', 'O'),\n",
              " ('son', 'O'),\n",
              " (')', 'O'),\n",
              " ('and', 'O'),\n",
              " ('tab', 'B-MINR'),\n",
              " ('##ath', 'B-MINR'),\n",
              " ('##a', 'B-MINR'),\n",
              " ('jones', 'I-MINR'),\n",
              " ('(', 'O'),\n",
              " ('daughter', 'O'),\n",
              " (')', 'O'),\n",
              " ('were', 'O'),\n",
              " ('found', 'O'),\n",
              " ('at', 'O'),\n",
              " ('their', 'O'),\n",
              " ('123', 'O'),\n",
              " ('main', 'O'),\n",
              " ('st', 'O'),\n",
              " ('.', 'O'),\n",
              " ('home', 'O'),\n",
              " ('and', 'O'),\n",
              " ('were', 'O'),\n",
              " ('later', 'O'),\n",
              " ('turned', 'O'),\n",
              " ('over', 'O'),\n",
              " ('to', 'O'),\n",
              " ('state', 'O'),\n",
              " ('services', 'O'),\n",
              " ('.', 'O'),\n",
              " ('tab', 'B-MINR'),\n",
              " ('##ath', 'B-MINR'),\n",
              " ('##a', 'B-MINR'),\n",
              " ('is', 'O'),\n",
              " ('10', 'O'),\n",
              " ('years', 'O'),\n",
              " ('old', 'O'),\n",
              " ('has', 'O'),\n",
              " ('a', 'O'),\n",
              " ('history', 'O'),\n",
              " ('of', 'O'),\n",
              " ('juvenile', 'O'),\n",
              " ('diabetes', 'O'),\n",
              " ('and', 'O'),\n",
              " ('requires', 'O'),\n",
              " ('specialized', 'O'),\n",
              " ('care', 'O'),\n",
              " ('.', 'O'),\n",
              " ('anthony', 'B-MINR'),\n",
              " ('is', 'O'),\n",
              " ('a', 'O'),\n",
              " ('new', 'O'),\n",
              " ('born', 'O'),\n",
              " ('and', 'O'),\n",
              " ('has', 'O'),\n",
              " ('a', 'O'),\n",
              " ('face', 'O'),\n",
              " ('only', 'O'),\n",
              " ('a', 'O'),\n",
              " ('mother', 'O'),\n",
              " ('can', 'O'),\n",
              " ('love', 'O'),\n",
              " ('.', 'O'),\n",
              " ('upon', 'O'),\n",
              " ('hearing', 'O'),\n",
              " ('of', 'O'),\n",
              " ('his', 'O'),\n",
              " ('children', 'O'),\n",
              " (\"'\", 'O'),\n",
              " ('s', 'O'),\n",
              " ('custody', 'O'),\n",
              " (',', 'O'),\n",
              " ('jose', 'B-MINR'),\n",
              " ('rec', 'O'),\n",
              " ('##ante', 'O'),\n",
              " ('##d', 'O'),\n",
              " ('his', 'O'),\n",
              " ('confession', 'O'),\n",
              " ('.', 'O'),\n",
              " ('[SEP]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O'),\n",
              " ('[PAD]', 'O')]"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "id": "Vr9FoBLl_oel",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "182ec04e-03d2-456e-849d-342e10efe592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-ad1449ac-680d-09dd-e240-8509fae72610)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-K5gU_wsXZ9P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}